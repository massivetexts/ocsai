{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ocsai.train import prepare_training_response, prepare_prompt, prepare_training_prompt, prepare_gpt_from_series\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "import openai\n",
    "from collections import defaultdict\n",
    "import tiktoken\n",
    "import time\n",
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/vg86l2h54czgjfzlmd6fkz908bdx0t/T/ipykernel_42523/1825289779.py:1: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('../data/ocsai-all.csv')\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../data/ocsai-all.csv')\n",
    "data_dir = Path('../data/training/gpt')\n",
    "data_dir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language  type        \n",
       "ara       uses              923\n",
       "chi       uses            16589\n",
       "dut       uses             7139\n",
       "eng       completion       2797\n",
       "          consequences     3195\n",
       "          instances        4448\n",
       "          metaphors        4341\n",
       "          uses            24954\n",
       "fre       uses             3400\n",
       "ger       uses            13687\n",
       "heb       uses              829\n",
       "ita       uses             8597\n",
       "pol       uses             7518\n",
       "rus       uses             1863\n",
       "spa       uses              783\n",
       "dtype: int64"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(['language', 'type']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Confidence Scores\n",
    "\n",
    "- 50% of scores are confidence=3\n",
    "- 25% of scores are confidence=2\n",
    "- 25% of scores are confidence=1\n",
    "\n",
    ">>> TO CONSIDER: THIS would tell people 25% of their data is suspect\n",
    "\n",
    "**ADD more bins??**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.  , 0.58, 0.82, 3.54])"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get quartile bins for data.rating_std\n",
    "bins = data.rating_std.quantile([.25, .5, .75, 1]).round(2).values\n",
    "bins[-1] = 5 # make the max bin something that wouldn't be hit\n",
    "bin_labels = list(range(len(bins)-1,0, -1))\n",
    "print(\"CONFIDENCE <-> RATING_STD BINS\")\n",
    "for i, lab in enumerate(bin_labels):\n",
    "    print(f\"Confidence {lab} is for stdev ranges {bins[i]}-{bins[i+1]}\")\n",
    "display(bins)\n",
    "data['confidence'] = pd.cut(data.rating_std, bins,\n",
    "                            include_lowest=True,\n",
    "                            labels=bin_labels)\n",
    "data[['rating_std', 'confidence']].sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.rating_std.hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different source, by confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>src</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>multiaut_dutch1/multiaut_dutch2</th>\n",
       "      <td>2.78</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiaut_german1</th>\n",
       "      <td>2.76</td>\n",
       "      <td>4934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiaut_italian2</th>\n",
       "      <td>2.75</td>\n",
       "      <td>5511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiaut_polish1</th>\n",
       "      <td>2.73</td>\n",
       "      <td>5051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiaut_italian1</th>\n",
       "      <td>2.71</td>\n",
       "      <td>3081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiaut_dutch2</th>\n",
       "      <td>2.71</td>\n",
       "      <td>753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiaut_russian1</th>\n",
       "      <td>2.68</td>\n",
       "      <td>1503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiaut_german3</th>\n",
       "      <td>2.67</td>\n",
       "      <td>5929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snb17</th>\n",
       "      <td>2.67</td>\n",
       "      <td>1337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiaut_russian2</th>\n",
       "      <td>2.61</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bs12</th>\n",
       "      <td>2.57</td>\n",
       "      <td>1248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>betal18</th>\n",
       "      <td>2.56</td>\n",
       "      <td>1281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiaut_dutch3</th>\n",
       "      <td>2.54</td>\n",
       "      <td>424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h18/setal08</th>\n",
       "      <td>2.54</td>\n",
       "      <td>6160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiaut_dutch4</th>\n",
       "      <td>2.51</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transdis</th>\n",
       "      <td>2.45</td>\n",
       "      <td>5014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>motesf</th>\n",
       "      <td>2.38</td>\n",
       "      <td>7751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiaut_polish1/multiaut_polish2</th>\n",
       "      <td>2.37</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h18/multiaut_english6/setal08/snbmo09</th>\n",
       "      <td>2.35</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiaut_dutch1</th>\n",
       "      <td>2.35</td>\n",
       "      <td>4898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dod20</th>\n",
       "      <td>2.34</td>\n",
       "      <td>3873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiaut_french4</th>\n",
       "      <td>2.31</td>\n",
       "      <td>1553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiaut_french3/multiaut_french4</th>\n",
       "      <td>2.30</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiaut_german2</th>\n",
       "      <td>2.28</td>\n",
       "      <td>2824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiaut_french3</th>\n",
       "      <td>2.24</td>\n",
       "      <td>1282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiaut_spanish1</th>\n",
       "      <td>2.24</td>\n",
       "      <td>769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hass17</th>\n",
       "      <td>2.22</td>\n",
       "      <td>424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h18/multiaut_english6/setal08</th>\n",
       "      <td>2.20</td>\n",
       "      <td>2261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snbmo09</th>\n",
       "      <td>2.16</td>\n",
       "      <td>2491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiaut_english2</th>\n",
       "      <td>2.13</td>\n",
       "      <td>2078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiaut_chinese1</th>\n",
       "      <td>2.11</td>\n",
       "      <td>10782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiaut_chinese2</th>\n",
       "      <td>2.11</td>\n",
       "      <td>561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiaut_polish2</th>\n",
       "      <td>2.09</td>\n",
       "      <td>2147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiaut_chinese2/transdis</th>\n",
       "      <td>2.00</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiaut_english3</th>\n",
       "      <td>1.95</td>\n",
       "      <td>1412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>motesp</th>\n",
       "      <td>1.87</td>\n",
       "      <td>928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiaut_english2/multiaut_english3</th>\n",
       "      <td>1.86</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmsl</th>\n",
       "      <td>1.85</td>\n",
       "      <td>2353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiaut_french2</th>\n",
       "      <td>1.61</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiaut_hebrew1</th>\n",
       "      <td>1.36</td>\n",
       "      <td>829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       mean   size\n",
       "src                                               \n",
       "multiaut_dutch1/multiaut_dutch2        2.78    194\n",
       "multiaut_german1                       2.76   4934\n",
       "multiaut_italian2                      2.75   5511\n",
       "multiaut_polish1                       2.73   5051\n",
       "multiaut_italian1                      2.71   3081\n",
       "multiaut_dutch2                        2.71    753\n",
       "multiaut_russian1                      2.68   1503\n",
       "multiaut_german3                       2.67   5929\n",
       "snb17                                  2.67   1337\n",
       "multiaut_russian2                      2.61    360\n",
       "bs12                                   2.57   1248\n",
       "betal18                                2.56   1281\n",
       "multiaut_dutch3                        2.54    424\n",
       "h18/setal08                            2.54   6160\n",
       "multiaut_dutch4                        2.51    451\n",
       "transdis                               2.45   5014\n",
       "motesf                                 2.38   7751\n",
       "multiaut_polish1/multiaut_polish2      2.37    320\n",
       "h18/multiaut_english6/setal08/snbmo09  2.35    186\n",
       "multiaut_dutch1                        2.35   4898\n",
       "dod20                                  2.34   3873\n",
       "multiaut_french4                       2.31   1553\n",
       "multiaut_french3/multiaut_french4      2.30    197\n",
       "multiaut_german2                       2.28   2824\n",
       "multiaut_french3                       2.24   1282\n",
       "multiaut_spanish1                      2.24    769\n",
       "hass17                                 2.22    424\n",
       "h18/multiaut_english6/setal08          2.20   2261\n",
       "snbmo09                                2.16   2491\n",
       "multiaut_english2                      2.13   2078\n",
       "multiaut_chinese1                      2.11  10782\n",
       "multiaut_chinese2                      2.11    561\n",
       "multiaut_polish2                       2.09   2147\n",
       "multiaut_chinese2/transdis             2.00    131\n",
       "multiaut_english3                      1.95   1412\n",
       "motesp                                 1.87    928\n",
       "multiaut_english2/multiaut_english3    1.86    138\n",
       "hmsl                                   1.85   2353\n",
       "multiaut_french2                       1.61    368\n",
       "multiaut_hebrew1                       1.36    829"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.confidence = pd.to_numeric(data.confidence)\n",
    "data[~data.confidence.isna()].groupby('src')['confidence'].aggregate(['mean', 'size']).sort_values('mean', ascending=False).query('size > 100').round(2).head(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic Prompt Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training prompts randomly mask parts of the full prompt, to encourage the model to get by without it.\n",
    "\n",
    "The confidence is based on the standard deviation of the human ratings: imperfect, but aiming for at least a bit of signal about the reliability of the rating.\n",
    "\n",
    "### Example Unmasked Prompt:\n",
    "\n",
    "```\n",
    "ACTION: TAG THE ORIGINALITY OF A RESPONSE TO A CREATIVITY TEST.\n",
    "TASK: uses\n",
    "PROMPT: علب الصفيح\n",
    "TASK QUESTION: ما هو الاستخدام المفاجئ لـ علب الصفيح؟\n",
    "LANGUAGE: ara\n",
    "RESPONSE: `آلات حادة`\n",
    "\n",
    "## Details\n",
    "SCALE: 1-5, where 1 is `not original at all` and 5 is `extremely original`\n",
    "FORMAT: Return in the format of newline-separated `KEY:value` pairs, with the following fields:\n",
    "- `SCORE`: An originality score, 1-5\n",
    "- `CONFIDENCE`: A measure of confidence in the score, 1-3, or None.\n",
    "- `FLAGS`: A comma-separated list with content flags, such as: 'nonsense', 'violent', 'not practical'\n",
    "```\n",
    "\n",
    "### Example Masked Prompt\n",
    "\n",
    "```\n",
    "TASK: uses\n",
    "PROMPT: علب الصفيح\n",
    "RESPONSE: `آلات حادة`\n",
    "```\n",
    "\n",
    "### Masking probabilities\n",
    "\n",
    "`task_exclude_prob=0.5, task_type_exclude_prob=0.3, prompt_exclude_prob=0, language_exclude_prob=0.5, question_exclude_prob=0.3, detail_exclude_prob=0.8`\n",
    "\n",
    "### Example Response\n",
    "\n",
    "```\n",
    "SCORE:2.0\n",
    "CONFIDENCE:1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTION: TAG THE ORIGINALITY OF A RESPONSE TO A CREATIVITY TEST.\n",
      "PROMPT: messy room\n",
      "TASK QUESTION: Think of the messiest room that you’ve ever had to live in. What was it like to live there?\n",
      "LANGUAGE: eng\n",
      "RESPONSE: `That room was like the inside of a child's mind`\n",
      "\n",
      "## Details\n",
      "SCALE: 1-5, where 1 is `not original at all` and 5 is `extremely original`\n",
      "FORMAT: Return in the format of newline-separated `KEY:value` pairs, with the following fields:\n",
      "- `SCORE`: An originality score, 1-5\n",
      "- `CONFIDENCE`: A measure of confidence in the score, 1-3, or None.\n",
      "----\n",
      "PROMPT: cegła\n",
      "TASK QUESTION: Jakie jest zaskakujące zastosowanie dla CEGŁY?\n",
      "LANGUAGE: pol\n",
      "RESPONSE: `brodzik`\n",
      "----\n",
      "TASK: uses\n",
      "PROMPT: Mülltüte\n",
      "TASK QUESTION: Was ist eine überraschende Verwendung für eine MÜLLTÜTE?\n",
      "LANGUAGE: ger\n",
      "RESPONSE: `Decke`\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    a = data.sample(frac=1).iloc[i]\n",
    "    p = prepare_training_prompt(a['prompt'], a['response'], a['type'], a['question'], a['language'],)\n",
    "    print(p)\n",
    "    print('----')\n",
    "    r = prepare_training_response(a['target'], a['confidence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Prompts For GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the expected new ChatCompletions format, via https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset:\n",
    "\n",
    "```\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the capital of France?\"}, {\"role\": \"assistant\", \"content\": \"Paris, as if everyone doesn't know that already.\"}]}\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Who wrote 'Romeo and Juliet'?\"}, {\"role\": \"assistant\", \"content\": \"Oh, just some guy named William Shakespeare. Ever heard of him?\"}]}\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"How far is the Moon from Earth?\"}, {\"role\": \"assistant\", \"content\": \"Around 384,400 kilometers. Give or take a few, like that really matters.\"}]}\n",
    "```\n",
    "\n",
    "There's a system message, user message, then an assistant message. These are saved in a JSONL file.\n",
    "\n",
    "Example, using `prepare_gpt_from_series`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'messages': [{'role': 'system',\n",
       "    'content': 'You are a creativity judge, scoring tests of originality.'},\n",
       "   {'role': 'user',\n",
       "    'content': 'TASK: uses\\nPROMPT: frozen\\nLANGUAGE: eng\\nRESPONSE: `snowman`'},\n",
       "   {'role': 'assistant', 'content': 'SCORE: 2.4\\nCONFIDENCE: 3'}]}]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(1).apply(prepare_gpt_from_series, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export test/validation/train data, as well as a small set for testing training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldata = data.sample(2000, random_state=42)\n",
    "smalldata.to_csv(data_dir / 'smalldata.csv', index=False)\n",
    "\n",
    "for df, suffix in [(smalldata, 'small'), (data, 'full')]:\n",
    "    for splitset in ['default_split']:\n",
    "        for split in ['train', 'val', 'test']:\n",
    "            subset = df[df['default_split'] == split]\n",
    "            # seed is not necessary here\n",
    "            jsonl = subset.apply(prepare_gpt_from_series, axis=1).tolist()\n",
    "            fname = data_dir / f\"{splitset}_{split}_{suffix}.jsonl\"\n",
    "            with open(fname, mode='w') as f:\n",
    "                # write jsonlines file\n",
    "                for j in jsonl:\n",
    "                    f.write(json.dumps(j))\n",
    "                    f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate Data Format\n",
    "\n",
    "via https://cookbook.openai.com/examples/chat_finetuning_data_prep\n",
    "\n",
    "Focus on the biggest file - the full training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples: 80770\n",
      "First example:\n",
      "{'role': 'system', 'content': 'You are a creativity judge, scoring tests of originality.'}\n",
      "{'role': 'user', 'content': 'TASK: uses\\nPROMPT: علب الصفيح\\nLANGUAGE: ara\\nRESPONSE: `آلات حادة`'}\n",
      "{'role': 'assistant', 'content': 'SCORE: 2.0'}\n"
     ]
    }
   ],
   "source": [
    "fname = data_dir / 'default_split_train_full.jsonl'\n",
    "\n",
    "# Load the dataset\n",
    "with open(fname, 'r', encoding='utf-8') as f:\n",
    "    dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Initial dataset stats\n",
    "print(\"Num examples:\", len(dataset))\n",
    "print(\"First example:\")\n",
    "for message in dataset[0][\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors found\n"
     ]
    }
   ],
   "source": [
    "# Format error checks\n",
    "format_errors = defaultdict(int)\n",
    "\n",
    "for ex in dataset:\n",
    "    if not isinstance(ex, dict):\n",
    "        format_errors[\"data_type\"] += 1\n",
    "        continue\n",
    "        \n",
    "    messages = ex.get(\"messages\", None)\n",
    "    if not messages:\n",
    "        format_errors[\"missing_messages_list\"] += 1\n",
    "        continue\n",
    "        \n",
    "    for message in messages:\n",
    "        if \"role\" not in message or \"content\" not in message:\n",
    "            format_errors[\"message_missing_key\"] += 1\n",
    "        \n",
    "        if any(k not in (\"role\", \"content\", \"name\", \"function_call\") for k in message):\n",
    "            format_errors[\"message_unrecognized_key\"] += 1\n",
    "        \n",
    "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
    "            format_errors[\"unrecognized_role\"] += 1\n",
    "            \n",
    "        content = message.get(\"content\", None)\n",
    "        function_call = message.get(\"function_call\", None)\n",
    "        \n",
    "        if (not content and not function_call) or not isinstance(content, str):\n",
    "            format_errors[\"missing_content\"] += 1\n",
    "    \n",
    "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "        format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "if format_errors:\n",
    "    print(\"Found errors:\")\n",
    "    for k, v in format_errors.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "else:\n",
    "    print(\"No errors found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# not exact!\n",
    "# simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "    return num_tokens\n",
    "\n",
    "def print_distribution(values, name):\n",
    "    print(f\"\\n#### Distribution of {name}:\")\n",
    "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples missing system message: 0\n",
      "Num examples missing user message: 0\n",
      "\n",
      "#### Distribution of num_messages_per_example:\n",
      "min / max: 3, 3\n",
      "mean / median: 3.0, 3.0\n",
      "p5 / p95: 3.0, 3.0\n",
      "\n",
      "#### Distribution of num_total_tokens_per_example:\n",
      "min / max: 49, 311\n",
      "mean / median: 97.1770335520614, 84.0\n",
      "p5 / p95: 64.0, 165.0\n",
      "\n",
      "#### Distribution of num_assistant_tokens_per_example:\n",
      "min / max: 6, 13\n",
      "mean / median: 12.640336758697536, 13.0\n",
      "p5 / p95: 13.0, 13.0\n",
      "\n",
      "0 examples may be over the 4096 token limit, they will be truncated during fine-tuning\n"
     ]
    }
   ],
   "source": [
    "# Warnings and tokens counts\n",
    "n_missing_system = 0\n",
    "n_missing_user = 0\n",
    "n_messages = []\n",
    "convo_lens = []\n",
    "assistant_message_lens = []\n",
    "\n",
    "for ex in dataset:\n",
    "    messages = ex[\"messages\"]\n",
    "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
    "        n_missing_system += 1\n",
    "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
    "        n_missing_user += 1\n",
    "    n_messages.append(len(messages))\n",
    "    convo_lens.append(num_tokens_from_messages(messages))\n",
    "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
    "    \n",
    "print(\"Num examples missing system message:\", n_missing_system)\n",
    "print(\"Num examples missing user message:\", n_missing_user)\n",
    "print_distribution(n_messages, \"num_messages_per_example\")\n",
    "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
    "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
    "n_too_long = sum(l > 4096 for l in convo_lens)\n",
    "print(f\"\\n{n_too_long} examples may be over the 4096 token limit, they will be truncated during fine-tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset has ~7848989 tokens that will be charged for during training\n",
      "By default, you'll train for 1 epochs on this dataset\n",
      "By default, you'll be charged for ~7848989 tokens\n"
     ]
    }
   ],
   "source": [
    "# Pricing and default n_epochs estimate\n",
    "MAX_TOKENS_PER_EXAMPLE = 4096\n",
    "\n",
    "TARGET_EPOCHS = 3\n",
    "MIN_TARGET_EXAMPLES = 100\n",
    "MAX_TARGET_EXAMPLES = 25000\n",
    "MIN_DEFAULT_EPOCHS = 1\n",
    "MAX_DEFAULT_EPOCHS = 25\n",
    "\n",
    "n_epochs = TARGET_EPOCHS\n",
    "n_train_examples = len(dataset)\n",
    "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
    "    n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
    "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
    "    n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
    "\n",
    "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
    "print(f\"Training dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
    "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
    "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated cost for training 1 epoch is $62.79\n",
      "Est with test/val: $78.49\n",
      "Est for 3 epochs: $235.47\n"
     ]
    }
   ],
   "source": [
    "base_cost = 0.0080 # per 1K\n",
    "est_cost_train = base_cost * n_epochs * n_billing_tokens_in_dataset / 1000\n",
    "print(f\"Estimated cost for training {n_epochs} epoch is ${est_cost_train:.2f}\")\n",
    "print(f\"Est with test/val: ${est_cost_train/.8:.2f}\")\n",
    "print(f\"Est for {n_epochs*3} epochs: ${3*est_cost_train/.8:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Train Data to GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5d5b0b03ce54cd8a9f9ad08c9b5e928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading ../data/training/gpt/default_split_val_small.jsonl\n",
      "Uploading ../data/training/gpt/default_split_train_full.jsonl\n",
      "Uploading ../data/training/gpt/default_split_test_full.jsonl\n",
      "Uploading ../data/training/gpt/default_split_val_full.jsonl\n",
      "Uploading ../data/training/gpt/default_split_train_small.jsonl\n",
      "Uploading ../data/training/gpt/default_split_test_small.jsonl\n",
      "files: dict_keys(['default_split_val_small.jsonl', 'default_split_train_full.jsonl', 'default_split_test_full.jsonl', 'default_split_val_full.jsonl', 'default_split_train_small.jsonl', 'default_split_test_small.jsonl'])\n"
     ]
    }
   ],
   "source": [
    "#@markdown Upload training files or retrieve already-trained files from OpenAI\n",
    "sid = dict()\n",
    "\n",
    "def upload_or_load(fname):\n",
    "    fname = Path(fname)\n",
    "    existing_files = [file for file in client.files.list() if file.filename == fname.name]\n",
    "    if len(existing_files):\n",
    "        print(f\"Using already uploaded file named {fname.name}. If this was unintended, delete the server one.\")\n",
    "        return existing_files[0].id\n",
    "    else:\n",
    "        print(\"Uploading\", fname)\n",
    "        with open(fname, mode='rb') as f:\n",
    "            results = client.files.create(\n",
    "                file=f,\n",
    "                purpose=\"fine-tune\"\n",
    "                )\n",
    "        return results.id\n",
    "\n",
    "for fname in tqdm(data_dir.glob(\"*jsonl\")):\n",
    "    sid[fname.name] = upload_or_load(fname)\n",
    "\n",
    "# to delete everything:\n",
    "# [client.files.delete(fid) for fid in sid.values()]\n",
    "    \n",
    "print(\"files:\", sid.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "set = 'full' # `small`` or `full``; small is a 1000 row subset to ensure everything works\n",
    "suffix = f'ocsai-{set}-1-24'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start training. Can't stop after this .. doublecheck that there's enough credit left on your account!\n",
    "\n",
    "*future note: validation may be unnecessary. At the costs involved, it's not likely that you're tinkering much.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = client.fine_tuning.jobs.create(\n",
    "  training_file=sid[f'default_split_train_{set}.jsonl'],\n",
    "  validation_file=sid[f'default_split_val_{set}.jsonl'],\n",
    "  suffix = suffix,\n",
    "  model=\"gpt-3.5-turbo-1106\"\n",
    ")\n",
    "\n",
    "# for reference: TO DELETE MODEL\n",
    "#client.models.delete('ft:gpt-3.5-turbo-1106:peter-organisciak:ocsai-small-1-24:8cfMjxJN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper parameters Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto')\n"
     ]
    }
   ],
   "source": [
    "print(\"Hyper parameters\", client.fine_tuning.jobs.retrieve(model.id).hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Retrieving fine-tune job...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Fine-tune ftjob-5Pbn7CQPO8u3z5SeNuq9IXSB has already been logged successfully at https://wandb.ai/massive-texts/OpenAI-Fine-Tune/runs/ftjob-5Pbn7CQPO8u3z5SeNuq9IXSB. Use `overwrite=True` if you want to overwrite previous run\n"
     ]
    }
   ],
   "source": [
    "from wandb.integration.openai.fine_tuning import WandbLogger\n",
    "WandbLogger.sync(fine_tune_job_id=model.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "succeeded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-5Pbn7CQPO8u3z5SeNuq9IXSB', created_at=1704319430, error=None, fine_tuned_model='ft:gpt-3.5-turbo-1106:peter-organisciak:ocsai-full-1-24:8d5RLryO', finished_at=1704326395, hyperparameters=Hyperparameters(n_epochs=1, batch_size=53, learning_rate_multiplier=2), model='gpt-3.5-turbo-1106', object='fine_tuning.job', organization_id='org-48rfjyoSnZfLJWOte33sjuqL', result_files=['file-Iq1Q3AeeXKStpPV4rKBJx9XI'], status='succeeded', trained_tokens=7687449, training_file='file-gTx9PdkFq4aaptjlRfoCptL6', validation_file='file-TB49njVn1PWGB5SHbH869Xc9')"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check in every few minutes to see training status\n",
    "while True:\n",
    "    status = client.fine_tuning.jobs.retrieve(model.id)\n",
    "    print(status.status)\n",
    "    if status.status not in ['running', 'pending', 'validating_files']:\n",
    "        break\n",
    "    if status.status == 'running':\n",
    "        time.sleep(60)\n",
    "    elif status.status in ['pending', 'validating_files']:\n",
    "        print(status)\n",
    "        time.sleep(5*60)\n",
    "    else:\n",
    "        break\n",
    "status\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"small\": \"ft:gpt-3.5-turbo-1106:peter-organisciak:ocsai-small-1-24:8cmALwWt\",\n",
    "    \"full\": \"ft:gpt-3.5-turbo-1106:peter-organisciak:ocsai-full-1-24:8d5RLryO\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For here, just evaluate on data that has been processed identically to the training data (with the same masking). Other conditions can be measured elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ocsai.train import GPT_SYS_MSG\n",
    "from ocsai.inference import GPT_Chat_Scorer\n",
    "scorer = GPT_Chat_Scorer(model_dict=models, cache='../data/test_cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 16.29it/s]\n",
      "checking ids on old files: 100%|██████████| 2/2 [00:00<00:00, 96.48it/s]\n",
      "checking ids on new files: 100%|██████████| 2/2 [00:00<00:00, 114.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking that all ids are preserved\n",
      "Original ids: 16908\n",
      "New ids: 16908\n",
      "All ids preserved, deleting old files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from ocsai.utils import upgrade_cache\n",
    "upgrade_cache('../data/test_cache', chunksize=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smalldata = pd.read_csv(data_dir / 'smalldata.csv')\n",
    "#testdata = smalldata[smalldata.default_split == 'test'].copy()\n",
    "#testdata = data[data.default_split == 'test'].sample(400, random_state=42).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall corr 0.56\n",
      "How well does predicted confidence correlate with actual confidence?\n",
      "0.12\n",
      "Correlation by predicted confidence\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>corr</th>\n",
       "      <th>p_val</th>\n",
       "      <th>conf_corr</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pol</th>\n",
       "      <th>uses</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    n  corr  p_val  conf_corr  rmse\n",
       "language type                                      \n",
       "pol      uses  1000.0  0.56    0.0       0.12  0.54"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scored['score'] = pd.to_numeric(all_scored['score'], errors='raise')\n",
    "all_scored['predict_confidence'] = pd.to_numeric(all_scored['predict_confidence'], errors='raise')\n",
    "\n",
    "print(\"overall corr\", all_scored[['target', 'score']].corr().round(2).iloc[0,1])\n",
    "\n",
    "print(\"How well does predicted confidence correlate with actual confidence?\")\n",
    "print(all_scored[['confidence', 'predict_confidence']].corr().round(2).iloc[0,1])\n",
    "\n",
    "print(\"Correlation by predicted confidence\")\n",
    "all_scored.groupby('predict_confidence')[['target', 'score']].corr().iloc[::2, 1].round(2)\n",
    "\n",
    "# correlation of target and score column\n",
    "from scipy.stats import pearsonr\n",
    "def stats(x):\n",
    "    corr, p_val, conf_corr = np.nan, np.nan, np.nan\n",
    "    nans = x[['target', 'score']].isna().any(axis=1)\n",
    "    if (~nans).sum() > 10:\n",
    "        corr, p_val = pearsonr(x[~nans]['target'], x[~nans]['score'])\n",
    "\n",
    "    nans = x[['confidence', 'predict_confidence']].isna().any(axis=1)\n",
    "    if (~nans).sum() > 10:\n",
    "        conf_corr = pearsonr(x[~nans]['confidence'], x[~nans]['predict_confidence'])[0]\n",
    "\n",
    "    return pd.Series({\n",
    "        'n': len(x),\n",
    "        'corr': np.round(corr, 2),\n",
    "        'p_val': np.round(p_val, 3),\n",
    "        'conf_corr': np.round(conf_corr, 2),\n",
    "        'rmse': np.round(np.sqrt(np.mean((x['target'] - x['score'])**2)), 3)\n",
    "    })\n",
    "x = all_scored.groupby(['language', 'type']).apply(stats)\n",
    "x[~x['corr'].isna()].sort_values('corr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.285911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.285911</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          target     score\n",
       "target  1.000000  0.285911\n",
       "score   0.285911  1.000000"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scored[all_scored['language'] == 'ara'][['target', 'score']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>corr</th>\n",
       "      <th>p_val</th>\n",
       "      <th>conf_corr</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ara</th>\n",
       "      <td>148.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chi</th>\n",
       "      <td>252.0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              n  corr  p_val  conf_corr   rmse\n",
       "language                                      \n",
       "ara       148.0  0.29    0.0        NaN  1.145\n",
       "chi       252.0  0.47    0.0      -0.04  0.418"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scored.groupby(['language']).apply(stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXqu-c24fsZs"
      },
      "source": [
        "This notebook combines all the datasets processed in [cleanDatasets.ipynb](cleanDatasets.ipynb). In the process, it does the following:\n",
        "\n",
        "- Analyzes some properties of duplication - e.g. how consistently duplicates are correlated\n",
        "- Combines the scores of duplicated responses into a single response\n",
        "- Deduplicates the responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ocsai.data import combine_dupes, fingerprint_series\n",
        "from ocsai.train import col_split, default_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(162872, 12)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>src</th>\n",
              "      <th>question</th>\n",
              "      <th>prompt</th>\n",
              "      <th>response</th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "      <th>participant</th>\n",
              "      <th>response_num</th>\n",
              "      <th>language</th>\n",
              "      <th>rater_count</th>\n",
              "      <th>rating_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1229</th>\n",
              "      <td>uses</td>\n",
              "      <td>multiaut_chinese1</td>\n",
              "      <td>什么是字典的一个令人惊讶的用途？</td>\n",
              "      <td>字典</td>\n",
              "      <td>做装饰品</td>\n",
              "      <td>multiaut_chinese1_字典-e9240b</td>\n",
              "      <td>2.6</td>\n",
              "      <td>multiaut_chinese11041</td>\n",
              "      <td>NaN</td>\n",
              "      <td>chi</td>\n",
              "      <td>4</td>\n",
              "      <td>0.816497</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      type                src          question prompt response  \\\n",
              "1229  uses  multiaut_chinese1  什么是字典的一个令人惊讶的用途？     字典     做装饰品   \n",
              "\n",
              "                               id  target            participant response_num  \\\n",
              "1229  multiaut_chinese1_字典-e9240b     2.6  multiaut_chinese11041          NaN   \n",
              "\n",
              "     language  rater_count  rating_std  \n",
              "1229      chi            4    0.816497  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import json\n",
        "\n",
        "data_dir = Path('../data/datasets')\n",
        "all_datasets = list(data_dir.glob('*.csv'))\n",
        "# concat and shuffle the data\n",
        "all_data = (pd.concat([pd.read_csv(f) for f in all_datasets])\n",
        "            .sample(frac=1, random_state=1234)\n",
        ")\n",
        "# remove start and end whitespace\n",
        "all_data.response = all_data.response.str.strip()\n",
        "# save for easy access later\n",
        "all_data.to_csv('../data/all_data.csv', index=False)\n",
        "print(all_data.shape)\n",
        "all_data.sample()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pre-dedupe data size is 162872 items\n",
            "# of unique participants is 9982\n",
            "# of unique prompts 252\n"
          ]
        }
      ],
      "source": [
        "# doublecheck no drop missing - the source data should already be clean\n",
        "assert all_data.prompt.isna().sum() == 0\n",
        "print(f\"Pre-dedupe data size is {len(all_data)} items\")\n",
        "print(f'# of unique participants is {len(all_data.participant.unique())}')\n",
        "print(\"# of unique prompts\", len(all_data.prompt.unique()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "src                type        \n",
              "multiaut_chinese1  uses            14176\n",
              "multiaut_dutch1    uses            10549\n",
              "multiaut_german1   uses             8116\n",
              "multiaut_german3   uses             8065\n",
              "transdis           uses             8007\n",
              "multiaut_polish1   uses             7415\n",
              "multiaut_italian2  uses             6895\n",
              "setal08            uses             5582\n",
              "h18                uses             5582\n",
              "dod20              uses             5490\n",
              "dbc23              metaphors        4589\n",
              "multiaut_italian1  uses             4269\n",
              "snbmo09            uses             4099\n",
              "hmsl               uses             3843\n",
              "multiaut_english2  uses             3723\n",
              "multiaut_german2   uses             3530\n",
              "multiaut_english6  uses             3425\n",
              "multiaut_english3  uses             3225\n",
              "h18                consequences     3198\n",
              "setal08            consequences     3198\n",
              "multiaut_polish2   uses             3054\n",
              "betal18            uses             2918\n",
              "motesf             uses             2913\n",
              "                   instances        2889\n",
              "                   completion       2761\n",
              "multiaut_spanish1  uses             2735\n",
              "h18                instances        2710\n",
              "setal08            instances        2710\n",
              "multiaut_dutch4    uses             2414\n",
              "snb17              uses             2372\n",
              "multiaut_french4   uses             2332\n",
              "multiaut_french3   uses             2181\n",
              "multiaut_hebrew1   uses             2027\n",
              "bs12               uses             1807\n",
              "multiaut_russian1  uses             1728\n",
              "multiaut_dutch2    uses             1640\n",
              "multiaut_arabic1   uses             1524\n",
              "multiaut_chinese2  uses             1302\n",
              "hass17             uses             1093\n",
              "multiaut_dutch3    uses             1004\n",
              "multiaut_french2   uses              449\n",
              "multiaut_russian2  uses              370\n",
              "motesp             uses              339\n",
              "                   instances         263\n",
              "                   completion        196\n",
              "                   consequences      165\n",
              "dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_data[['src', 'type']].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "# COMPLETION\n",
              "\n",
              "**Tests with this type:['motesf' 'motesp']**\n",
              "\n",
              "- Complete this sentence in a surprising way: \"When the kids were in the library...\"\n",
              "- Complete this sentence in a surprising way: \"When I got on the school bus...\"\n",
              "- Complete this sentence in a surprising way: \"At a sleepover we...\"\n",
              "- Complete this sentence in a surprising way: \"When I was at lunch...\"\n",
              "- Complete this sentence in a surprising way: \"When I opened my closet...\"\n",
              "- Complete this sentence in a surprising way: \"When the teacher was talking...\"\n",
              "- Complete this sentence in a surprising way: \"It started raining and...\"\n",
              "- Complete this sentence in a surprising way: \"My friend called me on the phone to tell me...\"\n",
              "- Complete this sentence in a surprising way: \"When the kids were in the library they found...\"\n",
              "- Complete this sentence in a surprising way: \"When I got on the school bus, I saw...\"\n",
              "- Complete this sentence in a surprising way: \"When I had a sleepover at my friend's, we played...\"\n",
              "- Complete this sentence in a surprising way: \"When the friends met in the playground, they...\"\n",
              "- Complete this sentence in a surprising way: \"When the teacher was talking, all the kids...\"\n",
              "# USES\n",
              "\n",
              "**Tests with this type:['multiaut_dutch1' 'snb17' 'transdis' 'multiaut_russian1'\n",
              " 'multiaut_english3' 'multiaut_chinese1' 'multiaut_dutch2' 'snbmo09'\n",
              " 'betal18' 'h18' 'hmsl' 'multiaut_polish1' 'multiaut_dutch4' 'dod20'\n",
              " 'multiaut_german1' 'multiaut_french2' 'multiaut_german3'\n",
              " 'multiaut_german2' 'multiaut_polish2' 'multiaut_hebrew1'\n",
              " 'multiaut_italian2' 'setal08' 'multiaut_french3' 'multiaut_spanish1'\n",
              " 'multiaut_english2' 'motesf' 'multiaut_italian1' 'bs12'\n",
              " 'multiaut_arabic1' 'multiaut_chinese2' 'multiaut_english6'\n",
              " 'multiaut_french4' 'multiaut_dutch3' 'hass17' 'multiaut_russian2'\n",
              " 'motesp']**\n",
              "\n",
              "- Wat is een verrassend gebruik voor een FORK?\n",
              "- What is a surprising use for ROPE?\n",
              "- 什么是牙刷的一个令人惊讶的用途？\n",
              "- Какое удивительное применение для ГАЗЕТА?\n",
              "- Wat is een verrassend gebruik voor een PAPERCLIP?\n",
              "- What is a surprising use for BOX?\n",
              "- 什么是衣架的一个令人惊讶的用途？\n",
              "- What is a surprising use for a BRICK?\n",
              "- 什么是筷子的一个令人惊讶的用途？\n",
              "- What is a surprising thing that is ROUND?\n",
              "- What is a surprising use for a KNIFE?\n",
              "- What is a surprising use for PAPERCLIP?\n",
              "- Jakie jest zaskakujące zastosowanie dla CEGŁA?\n",
              "- Wat is een verrassend gebruik voor een TOWEL?\n",
              "- Wat is een verrassend gebruik voor een BRICK?\n",
              "- What is a surprising use for TABLE?\n",
              "- 什么是钳子的一个令人惊讶的用途？\n",
              "- Was ist eine überraschende Verwendung für ein MESSER?\n",
              "- Was ist eine überraschende Verwendung für ein HAARFOEHN?\n",
              "- Quel est un usage surprenant pour un CHAPEAU?\n",
              "- Was ist eine überraschende Verwendung für ein TROMPETE?\n",
              "- Was ist eine überraschende Verwendung für ein BÜROKLAMMER?\n",
              "- Jakie jest zaskakujące zastosowanie dla PUSZKA?\n",
              "- מהו שימוש מפתיע למברג?\n",
              "- Qual è un uso sorprendente per un LIBRO?\n",
              "- What is a surprising use for BOOK?\n",
              "- 什么是西瓜的一个令人惊讶的用途？\n",
              "- 什么是吸管的一个令人惊讶的用途？\n",
              "- 什么是红酒的一个令人惊讶的用途？\n",
              "- Was ist eine überraschende Verwendung für ein KONSERVENDOSE?\n",
              "- 什么是图钉的一个令人惊讶的用途？\n",
              "- What is a surprising use for BRICK?\n",
              "- Quel est un usage surprenant pour un BROUETTE?\n",
              "- ¿Cuál es un uso sorprendente para un LADRILLO?\n",
              "- 什么是毛笔的一个令人惊讶的用途？\n",
              "- 什么是床单的一个令人惊讶的用途？\n",
              "- Was ist eine überraschende Verwendung für ein TROMMEL?\n",
              "- 什么是靴子的一个令人惊讶的用途？\n",
              "- What is a surprising use for PANTS?\n",
              "- What is a surprising use for a TOOTHBRUSH?\n",
              "- Was ist eine überraschende Verwendung für ein BETT?\n",
              "- 什么是椰子的一个令人惊讶的用途？\n",
              "- Qual è un uso sorprendente per un BOTTIGLIA DI PLASTICA?\n",
              "- Was ist eine überraschende Verwendung für ein SÄGE?\n",
              "- 什么是梳子的一个令人惊讶的用途？\n",
              "- מהו שימוש מפתיע לכיסא?\n",
              "- 什么是皮带的一个令人惊讶的用途？\n",
              "- Jakie jest zaskakujące zastosowanie dla SZNUREK?\n",
              "- ما هو استخدام مفاجئ لـ TIN CANS؟\n",
              "- What is a surprising use for FORK?\n",
              "- Qual è un uso sorprendente per un BARATTOLO?\n",
              "- 什么是光盘的一个令人惊讶的用途？\n",
              "- 什么是拖鞋的一个令人惊讶的用途？\n",
              "- 什么是狐狸的一个令人惊讶的用途？\n",
              "- Qual è un uso sorprendente per un ASPIRAPOLVERE?\n",
              "- 什么是易拉罐的一个令人惊讶的用途？\n",
              "- 什么是船桨的一个令人惊讶的用途？\n",
              "- Qual è un uso sorprendente per un MATTONE?\n",
              "- What is a surprising use for TIRE?\n",
              "- 什么是锅的一个令人惊讶的用途？\n",
              "- Was ist eine überraschende Verwendung für ein SCHAUFEL?\n",
              "- Какое удивительное применение для ДЕРЕВЯННАЯ ЛИНЕЙКА?\n",
              "- מהו שימוש מפתיע לסכין?\n",
              "- What is a surprising use for KNIFE?\n",
              "- Quel est un usage surprenant pour un CEINTURE?\n",
              "- 什么是头发的一个令人惊讶的用途？\n",
              "- Was ist eine überraschende Verwendung für ein PAPRIKA?\n",
              "- 什么是气球的一个令人惊讶的用途？\n",
              "- What is a surprising use for SHOE?\n",
              "- 什么是玉米的一个令人惊讶的用途？\n",
              "- 什么是茶壶的一个令人惊讶的用途？\n",
              "- Was ist eine überraschende Verwendung für ein SCHRANK?\n",
              "- Was ist eine überraschende Verwendung für ein GEIGE?\n",
              "- What is a surprising use for a HAT?\n",
              "- Was ist eine überraschende Verwendung für ein SEIL?\n",
              "- 什么是花瓣的一个令人惊讶的用途？\n",
              "- 什么是鹅卵石的一个令人惊讶的用途？\n",
              "- Qual è un uso sorprendente per un BOTTIGLIETTA?\n",
              "- 什么是墨水的一个令人惊讶的用途？\n",
              "- 什么是轮胎的一个令人惊讶的用途？\n",
              "- 什么是积木的一个令人惊讶的用途？\n",
              "- 什么是耳机的一个令人惊讶的用途？\n",
              "- Какое удивительное применение для КАРТОННАЯ КОРОБКА?\n",
              "- Was ist eine überraschende Verwendung für ein AXT?\n",
              "- 什么是铁链的一个令人惊讶的用途？\n",
              "- Qual è un uso sorprendente per un APPENDINO?\n",
              "- מהו שימוש מפתיע לנעל?\n",
              "- מהו שימוש מפתיע לקולב?\n",
              "- What is a surprising use for a LIGHT BULB?\n",
              "- Qual è un uso sorprendente per un SEDIA?\n",
              "- Was ist eine überraschende Verwendung für ein MÜLLTÜTE?\n",
              "- Qual è un uso sorprendente per un CESTINO?\n",
              "- 什么是窗帘的一个令人惊讶的用途？\n",
              "- Qual è un uso sorprendente per un ACCENDINO?\n",
              "- Was ist eine überraschende Verwendung für ein GURKE?\n",
              "- 什么是纽扣的一个令人惊讶的用途？\n",
              "- Qual è un uso sorprendente per un BOTTE?\n",
              "- 什么是硬币的一个令人惊讶的用途？\n",
              "- Qual è un uso sorprendente per un COLTELLO?\n",
              "- 什么是纸盒的一个令人惊讶的用途？\n",
              "- 什么是纸巾的一个令人惊讶的用途？\n",
              "- Qual è un uso sorprendente per un BARILE?\n",
              "- 什么是马来貘的一个令人惊讶的用途？\n",
              "- Qual è un uso sorprendente per un ATTACCAPANNI?\n",
              "- מהו שימוש מפתיע לעיפרון?\n",
              "- 什么是胶水的一个令人惊讶的用途？\n",
              "- 什么是手套的一个令人惊讶的用途？\n",
              "- Qual è un uso sorprendente per un CUCCHIAIO?\n",
              "- 什么是扇子的一个令人惊讶的用途？\n",
              "- 什么是扑克的一个令人惊讶的用途？\n",
              "- Qual è un uso sorprendente per un GUANTO?\n",
              "- מהו שימוש מפתיע לכרית?\n",
              "- מהו שימוש מפתיע לעיתון?\n",
              "- What is a surprising use for a BALL?\n",
              "- 什么是台灯的一个令人惊讶的用途？\n",
              "- Qual è un uso sorprendente per un GRAFFETTA?\n",
              "- Qual è un uso sorprendente per un ACCETTA?\n",
              "- Was ist eine überraschende Verwendung für ein FLÖTE?\n",
              "- Was ist eine überraschende Verwendung für ein STUHL?\n",
              "- Qual è un uso sorprendente per un CAPPELLO?\n",
              "- Qual è un uso sorprendente per un MARTELLO?\n",
              "- Qual è un uso sorprendente per un LAMPADINA?\n",
              "- 什么是银行卡的一个令人惊讶的用途？\n",
              "- Was ist eine überraschende Verwendung für ein ZANGE?\n",
              "- 什么是报纸的一个令人惊讶的用途？\n",
              "- 什么是酸奶的一个令人惊讶的用途？\n",
              "- What is a surprising use for BOTTLE?\n",
              "- 什么是柳树的一个令人惊讶的用途？\n",
              "- 什么是蜡烛的一个令人惊讶的用途？\n",
              "- 什么是花生的一个令人惊讶的用途？\n",
              "- 什么是音响的一个令人惊讶的用途？\n",
              "- 什么是杯子的一个令人惊讶的用途？\n",
              "- 什么是牙膏的一个令人惊讶的用途？\n",
              "- 什么是纸杯的一个令人惊讶的用途？\n",
              "- 什么是铅笔的一个令人惊讶的用途？\n",
              "- 什么是夹子的一个令人惊讶的用途？\n",
              "- What is a surprising use for SHOVEL?\n",
              "- 什么是橡皮擦的一个令人惊讶的用途？\n",
              "- Was ist eine überraschende Verwendung für ein ERBSE?\n",
              "- Qual è un uso sorprendente per un BANANA?\n",
              "- 什么是笛子的一个令人惊讶的用途？\n",
              "- Was ist eine überraschende Verwendung für ein TOMATE?\n",
              "- 什么是耳机线的一个令人惊讶的用途？\n",
              "- 什么是南瓜的一个令人惊讶的用途？\n",
              "- 什么是勺子的一个令人惊讶的用途？\n",
              "- 什么是柿子的一个令人惊讶的用途？\n",
              "- 什么是木头的一个令人惊讶的用途？\n",
              "- 什么是戒指的一个令人惊讶的用途？\n",
              "- What is a surprising use for a SOCK?\n",
              "- What is a surprising use for a PENCIL?\n",
              "- 什么是面团的一个令人惊讶的用途？\n",
              "- מהו שימוש מפתיע לצמיג?\n",
              "- 什么是盘子的一个令人惊讶的用途？\n",
              "- 什么是白纸的一个令人惊讶的用途？\n",
              "- What is a surprising use for a BOTTLE?\n",
              "- 什么是韭菜的一个令人惊讶的用途？\n",
              "- 什么是镊子的一个令人惊讶的用途？\n",
              "- 什么是酒瓶的一个令人惊讶的用途？\n",
              "- Was ist eine überraschende Verwendung für ein TISCH?\n",
              "- 什么是生姜的一个令人惊讶的用途？\n",
              "- 什么是磁铁的一个令人惊讶的用途？\n",
              "- 什么是灌木的一个令人惊讶的用途？\n",
              "- 什么是火柴的一个令人惊讶的用途？\n",
              "- 什么是卫生纸的一个令人惊讶的用途？\n",
              "- 什么是黄金的一个令人惊讶的用途？\n",
              "- 什么是相机的一个令人惊讶的用途？\n",
              "- 什么是喇叭的一个令人惊讶的用途？\n",
              "- 什么是钉子的一个令人惊讶的用途？\n",
              "- 什么是荷叶的一个令人惊讶的用途？\n",
              "- 什么是算盘的一个令人惊讶的用途？\n",
              "- 什么是水壶的一个令人惊讶的用途？\n",
              "- 什么是漏斗的一个令人惊讶的用途？\n",
              "- 什么是白酒的一个令人惊讶的用途？\n",
              "- 什么是地图的一个令人惊讶的用途？\n",
              "- 什么是芦荟的一个令人惊讶的用途？\n",
              "- 什么是画像的一个令人惊讶的用途？\n",
              "- 什么是塑料袋的一个令人惊讶的用途？\n",
              "- 什么是西瓜皮的一个令人惊讶的用途？\n",
              "- 什么是蛋壳的一个令人惊讶的用途？\n",
              "- 什么是花椒的一个令人惊讶的用途？\n",
              "- 什么是铃铛的一个令人惊讶的用途？\n",
              "- 什么是球拍的一个令人惊讶的用途？\n",
              "- 什么是擀面杖的一个令人惊讶的用途？\n",
              "- 什么是棉签的一个令人惊讶的用途？\n",
              "- 什么是无花果的一个令人惊讶的用途？\n",
              "- 什么是皮筋的一个令人惊讶的用途？\n",
              "- 什么是曲别针的一个令人惊讶的用途？\n",
              "- What is a surprising use for a SPOON?\n",
              "- 什么是领带的一个令人惊讶的用途？\n",
              "- 什么是贝壳的一个令人惊讶的用途？\n",
              "- 什么是土豆的一个令人惊讶的用途？\n",
              "- 什么是香蕉的一个令人惊讶的用途？\n",
              "- 什么是鞋带的一个令人惊讶的用途？\n",
              "- Qual è un uso sorprendente per un BORSA?\n",
              "- Qual è un uso sorprendente per un BICICLETTA?\n",
              "- 什么是蛋糕的一个令人惊讶的用途？\n",
              "- 什么是冰块的一个令人惊讶的用途？\n",
              "- 什么是袜子的一个令人惊讶的用途？\n",
              "- 什么是温度计的一个令人惊讶的用途？\n",
              "- 什么是发带的一个令人惊讶的用途？\n",
              "- 什么是字典的一个令人惊讶的用途？\n",
              "- 什么是牙签的一个令人惊讶的用途？\n",
              "- 什么是钥匙的一个令人惊讶的用途？\n",
              "- 什么是西红柿的一个令人惊讶的用途？\n",
              "- מהו שימוש מפתיע למטאטא?\n",
              "- 什么是围巾的一个令人惊讶的用途？\n",
              "- 什么是砖头的一个令人惊讶的用途？\n",
              "- 什么是橄榄油的一个令人惊讶的用途？\n",
              "- 什么是咖啡的一个令人惊讶的用途？\n",
              "- 什么是小米的一个令人惊讶的用途？\n",
              "- 什么是发簪的一个令人惊讶的用途？\n",
              "- 什么是核桃的一个令人惊讶的用途？\n",
              "- 什么是蛋清的一个令人惊讶的用途？\n",
              "- 什么是柳条的一个令人惊讶的用途？\n",
              "- What is a surprising use for a BACKPACK?\n",
              "- 什么是风车的一个令人惊讶的用途？\n",
              "- 什么是浴缸的一个令人惊讶的用途？\n",
              "- 什么是弹弓的一个令人惊讶的用途？\n",
              "- What is a surprising use for a SHOE?\n",
              "- 什么是毛巾的一个令人惊讶的用途？\n",
              "- 什么是蚊帐的一个令人惊讶的用途？\n",
              "- 什么是吹风机的一个令人惊讶的用途？\n",
              "- Qual è un uso sorprendente per un CAPELLO?\n",
              "# CONSEQUENCES\n",
              "\n",
              "**Tests with this type:['setal08' 'h18' 'motesp']**\n",
              "\n",
              "- What would be a surprising consequence if EVERYONE SHRANK TO 12 INCHES TALL?\n",
              "- What would be a surprising consequence if PEOPLE NEEDED NO SLEEP?\n",
              "- What would be a surprising consequence if YOUR TEACHER COULD READ MINDS?\n",
              "- What would be a surprising consequence if ALIENS LANDED AT YOUR SCHOOL?\n",
              "- What would be a surprising consequence if RAIN WAS MADE OF SODA?\n",
              "- What would be a surprising consequence if A KID WAS PRESIDENT?\n",
              "- What would be a surprising consequence if PEOPLE COULD TRAVEL THROUGH TIME?\n",
              "# METAPHORS\n",
              "\n",
              "**Tests with this type:['dbc23']**\n",
              "\n",
              "- Think of the most boring high-school or college class you’ve ever had. What was it like to sit through?\n",
              "- Think about the most disgusting thing you ever ate or drank. What was it like to eat or drink it?\n",
              "- Think about the worst movie or TV show you have ever seen. What was it like to watch it?\n",
              "- Think of the messiest room that you’ve ever had to live in. What was it like to live there?\n",
              "# INSTANCES\n",
              "\n",
              "**Tests with this type:['motesf' 'setal08' 'h18' 'motesp']**\n",
              "\n",
              "- What is a surprising example of something HUGE?\n",
              "- What is a surprising thing that makes a NOISE?\n",
              "- What is a surprising example of something FROZEN?\n",
              "- What is a surprising example of something RED?\n",
              "- What is a surprising example of something TASTY?\n",
              "- What is a surprising example of something WET?\n",
              "- What is a surprising example of something SOFT?\n",
              "- What is a surprising example of something FUN?\n",
              "- What is a surprising example of something SMELLY?\n",
              "- What is a surprising example of something BIG?\n",
              "- What is a surprising example of something COLD?\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s = \"\"\n",
        "for test_type in all_data['type'].astype(str).unique():\n",
        "    s += f\"# {test_type.upper()}\\n\\n\"\n",
        "    s += f\"**Tests with this type:{all_data[all_data.type == test_type].src.unique()}**\\n\\n\"\n",
        "    for q in all_data[all_data.type == test_type].question.unique():\n",
        "        s += f\"- {q}\\n\"\n",
        "\n",
        "from IPython.display import Markdown\n",
        "Markdown(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mbZjzsjIuW8"
      },
      "source": [
        "## Check Correlations among Duplicates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjzAueLF-G2j"
      },
      "source": [
        "Check correlation among ratings for responses which have been submitted more than once. Here, I sample one rating vs mean of all the ratings for a duplicate response. This contextualizes the max what a model might be able to do - if humans can't agree (sometimes with themselves!), then it would be impossible for a model to do so."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHONheN0k0Q4",
        "outputId": "9fe3e962-d1e5-4ce8-eb8d-e8114732ae5e"
      },
      "outputs": [],
      "source": [
        "#@markdown Average rating-to-rating correlation on duplicates\n",
        "# run multiple times with different samples\n",
        "from tqdm import trange\n",
        "corrs = []\n",
        "for i in trange(1000):\n",
        "    check_dupe_corr = all_data.sample(frac=1, random_state=i**2)\n",
        "    just_duped = check_dupe_corr[check_dupe_corr[['prompt', 'response']].duplicated(keep=False)]\n",
        "    first = just_duped.drop_duplicates(['prompt', 'response'], keep='first')\n",
        "    last = just_duped.drop_duplicates(['prompt', 'response'], keep='last')\n",
        "    merged = first.merge(last[['prompt', 'response', 'target']], how='inner', on=['prompt', 'response'])\n",
        "    corr = merged[['target_x', 'target_y']].corr().values[0,1]\n",
        "    corrs.append(corr)\n",
        "print(\"\\nAverage correlation among duplicates\", sum(corrs)/len(corrs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dM-KuLyz0gDx",
        "outputId": "cce1ab04-af6d-44c8-ecc1-26c21a7fa00b"
      },
      "outputs": [],
      "source": [
        "#@markdown Average rating-to-mean(other ratings) correlation on duplicates\n",
        "corrs = []\n",
        "for i in trange(1000):\n",
        "    check_dupe_corr = all_data.sample(frac=1)\n",
        "    means_of_dupes = check_dupe_corr[check_dupe_corr[['prompt', 'response']].duplicated()].groupby(['prompt','response'], as_index=False).target.mean().round(2)\n",
        "    corr = check_dupe_corr.merge(means_of_dupes[['prompt', 'response', 'target']], on=['prompt', 'response']).corr().loc['target_x', 'target_y']\n",
        "    corrs.append(corr)\n",
        "print(\"\\nAverage correlation among duplicates\", sum(corrs)/len(corrs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Merge Duplicates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTgfgBWR_c-H"
      },
      "source": [
        "Merge ratings for items with duplicates, so that a response that has been rated multiple times has the average of all instances as it's ground truth.\n",
        "\n",
        "First, set a de-duplication strategy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_data['dupe_control'] = fingerprint_series(all_data.response)\n",
        "# Fix chinese\n",
        "all_data.loc[all_data.language == 'chi', 'dupe_control'] = fingerprint_series(all_data.loc[all_data.language == 'chi', 'response'], basic=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Doublecheck Fingerprinting Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Doublecheck de-duplication algorithm. This was check *before* the fix line was added above.\n",
        "\n",
        "See which 'fingerprint' controlled responses have the most variants of a more basic\n",
        "'uncased match' version of the response. Then inspect the ones that vary the most.\n",
        "\n",
        "They tend to mostly be Polish, so easy to inspect for me.\n",
        "\n",
        "The big thing I'm checking for is false positives: does the fingerprinting produce anything that\n",
        "shouldn't be combines. Generally, the answer is 1) *no, the fingerprinting doesn't surface prominent errors., 2) except for Chinese*.\n",
        "\n",
        "Another check is whether meaning get changed. My judgement is *no*, it can be argued that 'she burped!!!!' is different from 'she burped', but likely not of enough import.\n",
        "\n",
        "One thing noticed was that 'podpórka' and 'подпорка' would be combined - a reminder to control by language when merging.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "podporka\n",
            "['podpórka' 'podpórka.' 'podpórka,' 'podporka' 'подпорка']\n",
            "\n",
            "wazon\n",
            "['wazon' 'wazon,' 'wazon.' \"wazon'\" '- wazon,']\n",
            "\n",
            "dlugopisy na pojemnik\n",
            "['pojemnik na długopisy' 'pojemnik na dlugopisy' 'pojemnik na długopisy.'\n",
            " 'pojemnik na dlugopisy,' 'pojemnik na długopisy...']\n",
            "\n",
            "jako podstawke\n",
            "['jako podstawkę' 'jako podstawkę.' 'jako podstawke' 'jako podstawkę,'\n",
            " 'jako podstawke ,']\n",
            "\n",
            "doniczka\n",
            "['doniczka' 'doniczka,' '- doniczka,' 'doniczka.' 'doniczką']\n",
            "\n",
            "polka\n",
            "['pólka' 'półka' 'polka' 'półka,']\n",
            "\n",
            "kubek\n",
            "['kubek' 'kubek.' 'kubek,' '- kubek,']\n",
            "\n",
            "jako popielniczke\n",
            "['jako popielniczkę' 'jako popielniczke' 'jako popielniczkę.'\n",
            " 'jako popielniczkę,']\n",
            "\n",
            "jako narzedzie zbrodni\n",
            "['jako narzędzie zbrodni.' 'jako narzędzie zbrodni,'\n",
            " 'jako narzedzie zbrodni.' 'jako narzędzie zbrodni']\n",
            "\n",
            "jako skarbonke\n",
            "['jako skarbonkę' 'jako skarbonke' 'jako skarbonkę,' 'jako skarbonkę.']\n",
            "\n",
            "do jako kwiatow wazon\n",
            "['do kwiatów jako wazon' 'jako wazon do kwiatów'\n",
            " '- jako wazon do kwiatów,' 'jako wazon do kwiatów,']\n",
            "\n",
            "swiecznik\n",
            "['świecznik' 'swiecznik' 'świecznik,' '- świecznik,']\n",
            "\n",
            "doniczke jako\n",
            "['jako doniczkę' 'jako doniczkę.' 'jako doniczke' 'jako doniczkę,']\n",
            "\n",
            "hold papers together\n",
            "['hold papers together' 'hold together papers.' 'hold papers together.'\n",
            " 'hold papers together!']\n",
            "\n",
            "zyrandol\n",
            "['żyrandol,' 'żyrandol' '- żyrandol,' 'zyrandol']\n",
            "\n",
            "podstawka\n",
            "['podstawka' 'podstawka,' 'podstawka.']\n",
            "\n",
            "jako podporke\n",
            "['jako podporke' 'jako podpórkę' 'jako podpórkę.']\n",
            "\n",
            "acid battery drink drinking like that was\n",
            "['that drink was like drinking battery acid'\n",
            " 'that drink was like drinking battery acid.'\n",
            " 'that drink was drinking like battery acid']\n",
            "\n",
            "do kwiatow wazon\n",
            "['wazon do kwiatów,' 'wazon do kwiatów' 'wazon do kwiatow']\n",
            "\n",
            "rice\n",
            "['rice.' 'rice' 'rice?']\n",
            "\n",
            "all ate books the they\n",
            "['they ate all the books.' 'they ate all the books'\n",
            " 'they ate all the books!']\n",
            "\n",
            "na popielniczke\n",
            "['na popielniczkę' 'na popielniczke' 'na popielniczkę.']\n",
            "\n",
            "jako zabawke\n",
            "['jako zabawkę' 'jako zabawke' 'jako zabawkę.']\n",
            "\n",
            "taboret\n",
            "['taboret,' 'taboret.' 'taboret']\n",
            "\n",
            "ozdobe\n",
            "['ozdobe' 'ozdobe,' 'ozdobę']\n",
            "\n",
            "odwaznik\n",
            "['odważnik,' 'odważnik' 'odważnik.']\n",
            "\n",
            "ciezarek\n",
            "['ciężarek' 'ciężarek,' 'ciezarek']\n",
            "\n",
            "ksiazke pod podporka\n",
            "['podpórka pod ksiazke' 'podporka pod ksiazke' 'podpórka pod książkę']\n",
            "\n",
            "na zlom\n",
            "['na złom,' 'na złom' 'na złom.']\n",
            "\n",
            "rzezba\n",
            "['rzeźba' 'rzezba' 'rzeżba']\n",
            "\n",
            "do papieru przycisk\n",
            "['przycisk do papieru' 'przycisk do papieru.' ', przycisk do papieru']\n",
            "\n",
            "abazur\n",
            "['abażur' 'abazur' 'abażur,']\n",
            "\n",
            "podkladka\n",
            "['podkładka,' 'podkładka' 'podkładka ,']\n",
            "\n",
            "kubek zrobic\n",
            "['zrobic kubek' 'zrobić kubek' 'zrobić kubek,']\n",
            "\n",
            "bron\n",
            "['broń' 'bron' 'broń,']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "all_data['basic_control'] = all_data.response.str.lower()\n",
        "top_variants = all_data[['dupe_control', 'basic_control']].drop_duplicates().dupe_control.value_counts()\n",
        "for fp in top_variants.index[:35]:\n",
        "    print(fp)\n",
        "    print(all_data[all_data.dupe_control == fp].basic_control.unique())\n",
        "    print()\n",
        "all_data.drop(columns=['basic_control'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_data['dupe_control_fp'] = all_data['dupe_control'].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Combine human judgements for duplicate responses\n",
        "\n",
        "If a response shows up multiple times in the dataset and has been rated by judges multiple times, combine the judgements. Multiple rater judgements for a specific response have already been averaged before this data was loaded, so the current step essentially averages the averages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3bff96e3987645e59f44456d3af28d33",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/103773 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# based on a grouping of language+type+question+prompt+dupe_control, combine duplicate rows,\n",
        "# with the following strategies for combining the remaining rows:\n",
        "from tqdm.auto import tqdm\n",
        "tqdm.pandas()\n",
        "groupcols = ['language', 'type', 'question', 'prompt', 'dupe_control']\n",
        "dedupe = all_data.groupby(groupcols, as_index=False).progress_apply(combine_dupes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Folded 162872 rows into 103773 deduped rows (63.71%)\n"
          ]
        }
      ],
      "source": [
        "og_size = len(all_data)\n",
        "deduped_size = len(dedupe)\n",
        "print(\"Folded {} rows into {} deduped rows ({}%)\".format(og_size, deduped_size, round(deduped_size/og_size*100, 2)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save\n",
        "dedupe.to_csv('../data/dedupe.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Caveats\n",
        "\n",
        "This is a good faith deduplication, folding together exact duplicate responses, as well as near duplicates.\n",
        "\n",
        "However, large language models are smart enough to understand completely different sentences with the near-identical sentiment (e.g. 'the feline leaped' vs. 'the cat jumped'). That *isn't* controlled by this deduplication.\n",
        "\n",
        "Another thing that is not controlled by the deduplication is when the same response occurs in a different language.\n",
        "\n",
        "For example, an un-original response for 'toothbrush' (brush your teeth) may occur in english, which the identical use for 牙刷  (刷牙) in chinese. However, at least post duplication there's only one of each in the dataset, rather than 20 occurrences of the english response and 178 occurrences in the chinese data, as in the original data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split Dataset\n",
        "\n",
        "Rather than creating a bunch of different datasets for different splits, I'll pre-process a number of sensible splits at once and save them as different columns.\n",
        "\n",
        "Split reference:\n",
        "\n",
        "- `default_split`: an 80/5/15 split, entirely randomized by row\n",
        "- `prompt_split`: a condition where prompts are either in train or val+test, but not both. For evaluating whether a model trained on some models can perform well on new prompts.\n",
        "- `lang_split`: a condition where train is English and evaluation is other languages. AUT only.\n",
        "- `type_split`: a condition where training is only on AUT, and evaluation is on other tasks.\n",
        "- `participant_split`: a condition where participants are wholly in train, val, or test. Not currently crunched, because it's complicated by deduping."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Unfinished below*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "14781"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dedupe.loc[dedupe.type!='uses', 'lang_split'].isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "random_seed = 987\n",
        "dedupe['default_split'] = default_split(len(dedupe), random_seed=random_seed)\n",
        "dedupe['prompt_split'] = col_split(dedupe['prompt'], random_seed=random_seed, include_in_train=['brick'])\n",
        "# train_size=0 just means that we stop adding to the training set after including the 'include_in_train' items\n",
        "dedupe['lang_split'] = col_split(dedupe['language'], random_seed=random_seed,\n",
        "                                 train_size=0, include_in_train=['eng']) \n",
        "dedupe.loc[dedupe.type!='uses', 'lang_split'] = pd.NA\n",
        "dedupe['type_split'] = col_split(dedupe['type'], random_seed=random_seed,\n",
        "                                 train_size=0, include_in_train=['uses'])\n",
        "dedupe.to_csv('../data/ocsai-all.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHocMN_pQABA"
      },
      "source": [
        "# Dataset Reference\n",
        "\n",
        "####gt_main2\n",
        "\n",
        "This is the main split in the first LLM paper.\n",
        "\n",
        "- Data size is 20202 items\n",
        "- seed 987\n",
        "- targetsplits {'train': 80, 'val': 5, 'test': 15}\n",
        "- split_by_part: False; split_by_prompt: False\n",
        "- Final split sizes: [80.0, 5.0, 15.0]\n",
        "- (gt_main_std *should* be identical, with stdev included, but I haven't doublechecked)\n",
        "\n",
        "####gt_byparticipant\n",
        "- Data size is 20202 items\n",
        "- seed 987\n",
        "- targetsplits {'train': 80, 'val': 5, 'test': 15}\n",
        "- split_by_part: True; split_by_prompt: False\n",
        "- Final split sizes: [80.7, 4.7, 14.6]\n",
        "\n",
        "####gt_byprompt\n",
        "\n",
        "This the the split used for having different prompts between test and train in the first LLM paper.\n",
        "\n",
        "- Data size is 20202 items\n",
        "- seed 987\n",
        "- targetsplits {'train': 79, 'val': 4, 'test': 17}\n",
        "- split_by_part: False; split_by_prompt: True\n",
        "- train: ['brick', 'box', 'knife', 'rope', 'book', 'table', 'tire', 'fork', 'ball', 'pencil', 'lightbulb', 'shoe', 'hat', 'sock', 'toothbrush', 'backpack']\n",
        "- val: []\n",
        "- test: ['paperclip', 'spoon', 'bottle', 'shovel', 'pants']\n",
        "- Final split sizes: [83.2, 0.0, 16.8]\n",
        "\n",
        "####all\n",
        "\n",
        "This is the condition for training the final model, for use in the Open Creativity Scoring system. It was *not* deduped for training to avoid data leakeage, since it's for applied use and that performance would be desired.\n",
        "\n",
        "- Data size is 27217 items\n",
        "- seed 987\n",
        "- targetsplits {'train': 94, 'val': 1, 'test': 5}\n",
        "- split_by_part: False; split_by_prompt: False\n",
        "- Final split sizes: [94.0, 1.0, 5.0]\n",
        "\n",
        "####gt_alltests2\n",
        "\n",
        "This is the condition which includes consequences, instances, and complete the sentence. It may grow outdated as I develop a format for training with this data.\n",
        "\n",
        "It doesn't have test/train, rather multiple numbered groups so that an ensemble can be trained.\n",
        "\n",
        "- Data size is 31567 items\n",
        "- seed 987\n",
        "- targetsplits {'group1': 32, 'group2': 32, 'group3': 32, 'val': 4}\n",
        "- split_by_part: False; split_by_prompt: False\n",
        "- Final split sizes: [32.0, 32.0, 32.0, 4.0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJon5X15GaV4",
        "outputId": "d9d0e19e-ead5-4f01-e524-ca2cb4eec923"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All gt options\n",
            "['gt_main', 'gt_bypart3', 'gt_byprompt4', 'gt_byparticipant', 'gt_byprompt', 'all', 'gt_main2', 'gt_main_std', 'gt_alltests1']\n"
          ]
        }
      ],
      "source": [
        "dprint(\"All gt options\")\n",
        "print([x.stem.split('.')[0] for x in base_dir.glob('*tar.gz')])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyP/4DeAWbHGaXxKUYl0C2Du",
      "collapsed_sections": [
        "zltQcwkXeRvk",
        "vJqyd2UHDCMZ",
        "UH3yOwIon4Ky",
        "VgNoUTqg_dQb",
        "laa40OuiNV2X",
        "8H-WPj9MeGrS",
        "9mbZjzsjIuW8"
      ],
      "include_colab_link": true,
      "mount_file_id": "1bZ0PDifSqhWhAUwuLK4BCt0Mke50ww-Q",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
